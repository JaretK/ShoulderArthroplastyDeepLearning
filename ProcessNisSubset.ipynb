{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ludwig.api import LudwigModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "dataset = \"../MERGED_1998_2014_TSA.csv\"\n",
    "data = pd.read_csv(dataset, dtype = {\n",
    "    'dispuniform':object,\n",
    "    'female':object,\n",
    "    'age':object,\n",
    "    'h_contrl':object,\n",
    "    'year': np.int32,\n",
    "    'tran_in':object\n",
    "}, low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for column processing\n",
    "def convert_payer(row):\n",
    "    val = str(row['pay1'])\n",
    "    if val == '1':\n",
    "        return 'Medicare'\n",
    "    if val == '2':\n",
    "        return 'Medicaid'\n",
    "    if val == '3':\n",
    "        return 'Private'\n",
    "    if val == '4':\n",
    "        return 'Self-pay'\n",
    "    else:\n",
    "        return 'Other'\n",
    "def convert_race(row):\n",
    "    val = str(row['race'])\n",
    "    conversions = {\n",
    "        '1':'White',\n",
    "        '2':'Black',\n",
    "        '3':'Hispanic',\n",
    "        '4':'Asian or Pacific Islander',\n",
    "        '5':'Native American',\n",
    "        '6':'Other'\n",
    "    }\n",
    "    for x in conversions.keys():\n",
    "        if val == x:\n",
    "            return conversions[x]\n",
    "    return 'Unknown'\n",
    "\n",
    "def convert_ownership(h_contrl):\n",
    "    conversions = {\n",
    "        '1':'Government, nonfederal',\n",
    "        '2':'Private not-profit',\n",
    "        '3':'Private invest-own'\n",
    "    }\n",
    "    for x in conversions.keys():\n",
    "        if h_contrl == x:\n",
    "            return conversions[x]\n",
    "        \n",
    "def code_arthritis(row):\n",
    "    dx_cols = ['dx1', 'dx2', 'dx3', 'dx4', 'dx5', 'dx6', 'dx7', 'dx8', 'dx9', 'dx10', 'dx11', 'dx12', 'dx13', 'dx14', 'dx15', 'dx16', 'dx17', 'dx18', 'dx19', 'dx20', 'dx21', 'dx22', 'dx23', 'dx24', 'dx25', 'dx26', 'dx27', 'dx28', 'dx29', 'dx30']\n",
    "    # 71[456]\\d\\d = arthritis\n",
    "    # 711[1-8]\\d = arthropathy\n",
    "    # 712\\d\\d = crystal arthropathy\n",
    "    # 6960 = psoriatic arthropathy\n",
    "    # 73340 = Aseptic necrosis, NOS\n",
    "    # 73341 = Aseptic necrosis of head of humerus\n",
    "    # 73349 = Aseptic necrosis of bone, other\n",
    "    # technically not arthritis, but surgical operation should be similar\n",
    "    # 73381 Malunion of fracture\n",
    "    # 73382 Nonunion of fracture\n",
    "    # 9052 Late effect of fracture of upper extremities\n",
    "    # 71880\tOther joint derangement, not elsewhere classified, site unspecified\n",
    "    # 71881\tOther joint derangement, not elsewhere classified, shoulder region\n",
    "    # 72610 Disorders of bursae and tendons in shoulder region, unspecified\n",
    "    # 72761 Complete rupture of rotator cuff\n",
    "    # 8407\tSuperior glenoid labrum lesion\n",
    "    # 71831 = Recurrent dislocation of joint, shoulder region\n",
    "    \n",
    "    # I AM PURPOSEFULLY NOT INCLUDING PRIMARY / SECONDARY NEOPLASMS OF BONE\n",
    "    regexes = [r'^71[456]\\d+',r'^71[45]\\d+',r'^711[12345678]\\d+',r'^712\\d+',\n",
    "               r'^6960',r'7334[019]', r'^72761', r'^7338[12]', r'^9052$',\n",
    "               r'^7188[01]', r'^72610', r'^72761', r'^8407$', r'^71831$']\n",
    "    for col in dx_cols:\n",
    "        for regex in regexes:\n",
    "            if re.search(regex, str(row[col])):\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def code_hardware_failure(row):\n",
    "    dx_cols = ['dx1', 'dx2', 'dx3', 'dx4', 'dx5', 'dx6', 'dx7', 'dx8', 'dx9', 'dx10', 'dx11', 'dx12', 'dx13', 'dx14', 'dx15', 'dx16', 'dx17', 'dx18', 'dx19', 'dx20', 'dx21', 'dx22', 'dx23', 'dx24', 'dx25', 'dx26', 'dx27', 'dx28', 'dx29', 'dx30']\n",
    "    # 99640 Unspecified mechanical complication of internal orthopedic device, implant, and graft \n",
    "    # 99641 Mechanical loosening of prosthetic joint \n",
    "    # 99642 Dislocation of prosthetic joint \n",
    "    # 99643 Broken prosthetic joint implant \n",
    "    # 99644 Peri-prosthetic fracture around prosthetic joint \n",
    "    # 99645 Peri-prosthetic osteolysis \n",
    "    # 99646 Articular bearing surface wear of prosthetic joint \n",
    "    # 99647 Other mechanical complication of prosthetic joint implant \n",
    "    # 99649 Other mechanical complication of other internal orthopedic device, implant, and graft \n",
    "    # 99666 Infection and inflammatory reaction due to internal joint prosthesis\n",
    "    # 99667 Infection and inflammatory reaction due to other internal orthopedic device, implant, and graft\n",
    "    # 99677\tOther complications due to internal joint prosthesis\n",
    "    # 99678\tOther complications due to other internal orthopedic device, implant, and graft\n",
    "    regexes = [r'^9964\\d?', r'9966[67]', r'^9967[78]$']\n",
    "    for col in dx_cols:\n",
    "        for regex in regexes:\n",
    "            if re.search(regex, str(row[col])):\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def code_trauma(row):\n",
    "    # it is easier to code external causes of injury by CCS classifications instead of ICD9 E codes\n",
    "    e_cols = ['e_ccs1','e_ccs2','e_ccs3','e_ccs4']\n",
    "    # 2603 = fall\n",
    "    # 2606 = machinery\n",
    "    # 2607 = motor vehicle traffic injury\n",
    "    # 2608 = pedal cyclist not MVT\n",
    "    # 2609 = pedestrian, not MVT\n",
    "    # 2610 = transport, not MVT\n",
    "    # 2614 = struck by - against\n",
    "    # 2619 = other specified\n",
    "    # 2620 = Unspecified\n",
    "    trauma_codes = ['2603', '2606', '2607', \n",
    "                    '2608', '2609', '2610',\n",
    "                    '2614', '2619','2620']\n",
    "\n",
    "    for col in e_cols:\n",
    "        for trauma_cause in trauma_codes:\n",
    "            if str(row[col]) == trauma_cause:\n",
    "                return 1\n",
    "    # some require ICD 9 codes\n",
    "    dx_cols = ['dx1', 'dx2', 'dx3', 'dx4', 'dx5', 'dx6', 'dx7', 'dx8', 'dx9', 'dx10', 'dx11', 'dx12', 'dx13', 'dx14', 'dx15', 'dx16', 'dx17', 'dx18', 'dx19', 'dx20', 'dx21', 'dx22', 'dx23', 'dx24', 'dx25', 'dx26', 'dx27', 'dx28', 'dx29', 'dx30']\n",
    "\n",
    "    # 81[2][0123]\\d = superior humeral fractures \n",
    "    # 831[01]\\d = shoulder dislocations  \n",
    "    # 73311 = pathologic fracture of humerus\n",
    "    # 73310 = pathologic fracture unspecified\n",
    "    # 73319 = Pathologic fracture of other specified site\n",
    "    fracture_codes = [r'^81[2][0123]\\d', r'^831[01]\\d',r'^7331[019]']\n",
    "    for col in dx_cols:\n",
    "        for regex in fracture_codes:\n",
    "            if re.search(regex, str(row[col])):\n",
    "                return 1\n",
    "            \n",
    "    return 0\n",
    "\n",
    "def include(row):\n",
    "    if int(row['arthritis']) == 0 and int(row['hardware_failure']) == 0 and int(row['trauma']) == 0:\n",
    "        return 0\n",
    "    return 1\n",
    "    \n",
    "\n",
    "def split_train_val_test(df, train_frac, val_frac, test_frac, random_seed = 42):\n",
    "    np.random.seed(random_seed)\n",
    "    pass_sum_test = round(train_frac + val_frac + test_frac, 5) == 1.0\n",
    "    if not pass_sum_test:\n",
    "        raise ValueError('Train val test must sum to 1.0')\n",
    "    pass_sign_test = (train_frac >= 0.0) and (val_frac >= 0.0) and (test_frac >= 0.0)\n",
    "    if not pass_sign_test:\n",
    "        raise ValueError('Train_frac, val_frac, test_frac must be >= 0 ')\n",
    "    converted_test_fraction = 1.0 - test_frac\n",
    "    train, validate, test = np.split(df.sample(frac=1), [int(train_frac*len(df)), int(converted_test_fraction*len(df))])\n",
    "    return train, validate, test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process dataset\n",
    "# drop columns\n",
    "data = data[data.died != \"A\"] #77 droped\n",
    "\"\"\"\n",
    "drop based on dispuniform\n",
    "A = Invalid\n",
    "99 = Unknown\n",
    "\"\"\"\n",
    "data = data[data.dispuniform != 'A']\n",
    "data = data[data.dispuniform != '99']\n",
    "data = data[data.los != 'A']\n",
    "data = data[data.los != 'C']\n",
    "data['los'] = data['los'].apply(pd.to_numeric)\n",
    "data = data[data.female != \"C\"]\n",
    "data = data[data.age != \"C\"]\n",
    "data['age'] = data['age'].apply(pd.to_numeric)\n",
    "data = data[data.year >= 2003] # e codes not implemented until 2003\n",
    "data = data[data.age >= 18]\n",
    "data = data[data.neomat == 0]\n",
    "data = data[data.pay1 != 'A']\n",
    "data = data[data.hospbrth == 0]\n",
    "data = data[pd.notnull(data.amonth)]\n",
    "data['amonth'] = data['amonth'].apply(pd.to_numeric)\n",
    "data = data[pd.notnull(data.hosp_bedsize)]\n",
    "data = data[pd.notnull(data.hosp_locteach)]\n",
    "data = data[pd.notnull(data.h_contrl)]\n",
    "data = data[data.elective != 'A']\n",
    "data = data[data.zipincgrp != 'A']\n",
    "\n",
    "# assign new columns\n",
    "dx_cols = ['dx1', 'dx2', 'dx3', 'dx4', 'dx5', 'dx6', 'dx7', 'dx8', 'dx9', 'dx10', 'dx11', 'dx12', 'dx13', 'dx14', 'dx15', 'dx16', 'dx17', 'dx18', 'dx19', 'dx20', 'dx21', 'dx22', 'dx23', 'dx24', 'dx25', 'dx26', 'dx27', 'dx28', 'dx29', 'dx30']\n",
    "data['combined_dx'] = data[dx_cols].apply(lambda row: ' '.join(row.values.astype(str)).replace('nan','').strip(), axis=1)\n",
    "ecode_cols = ['ecode1','ecode2','ecode3','ecode4']\n",
    "data['combined_e_codes'] = data[ecode_cols].apply(lambda row: ' '.join(row.values.astype(str)).replace('nan','').strip(), axis=1)\n",
    "pr_cols = ['pr1', 'pr2', 'pr3', 'pr4', 'pr5', 'pr6', 'pr7', 'pr8', 'pr9', 'pr10', 'pr11', 'pr12', 'pr13', 'pr14', 'pr15']\n",
    "data['planned_pr'] = data[pr_cols].apply(lambda row: ' '.join(row.values.astype(str)).replace('nan','').strip(), axis=1)\n",
    "\n",
    "# code cases\n",
    "data['arthritis'] = data.apply(code_arthritis, axis = 1)\n",
    "data['hardware_failure'] = data.apply(code_hardware_failure, axis = 1) \n",
    "data['trauma'] = data.apply(code_trauma, axis = 1)\n",
    "data['include'] = data.apply(include, axis = 1)\n",
    "\n",
    "\n",
    "data['admit_month_str'] = data.apply(lambda row: datetime.date(1900, int(row['amonth']), 1).strftime('%B'), axis=1)\n",
    "data[\"sex\"] = ['Male' if x == '0' else \"Female\" for x in data['female']]\n",
    "data['payer'] = data.apply(convert_payer, axis=1)\n",
    "data['race_converted'] = data.apply(convert_race, axis = 1)\n",
    "data['h_contrl_converted'] = data['h_contrl'].apply(convert_ownership)\n",
    "data[\"tran_in_condensed\"] = ['0' if x == '0' else \"1\" for x in data['tran_in']]\n",
    "\n",
    "# remove patients with LOS > 99%ile (NOT removing LOS < 1% because LOS is left censored)\n",
    "top_los = data.los.quantile(0.99)\n",
    "# remove patients with total charges < 1% or > 99% \n",
    "bottom_charges = data.totchg_2014_normalized.quantile(0.01)\n",
    "top_charges = data.totchg_2014_normalized.quantile(0.99)\n",
    "\n",
    "# remove patients by los and charges\n",
    "data = data[data.los < top_los]\n",
    "data = data[data.totchg_2014_normalized > bottom_charges]\n",
    "data = data[data.totchg_2014_normalized < top_charges]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert output columns\n",
    "data['disp_routine'] = [1 if x == '1' else 0 for x in data['dispuniform']]\n",
    "data['los_2'] = [1 if x > 2 else 0 for x in data['los']]\n",
    "data['totcost2014_3'] = pd.qcut(data.totcost2014, 3, labels = {'Low', 'Medium', 'High'})\n",
    "data['totchg_2014_normalized_3'] = pd.qcut(data.totchg_2014_normalized, 3, labels = {'Low', 'Medium', 'High'})\n",
    "\n",
    "# make z score columns\n",
    "data['totcost2014_zscore'] = (data['totcost2014'] - data['totcost2014'].mean())/(data['totcost2014'].std(ddof=0))\n",
    "data['los_zscore'] = (data['los'] - data['los'].mean())/(data['los'].std(ddof=0))\n",
    "data['totchg_2014_normalized_zscore'] = (data['totchg_2014_normalized'] - data['totchg_2014_normalized'].mean())/(data['totchg_2014_normalized'].std(ddof=0))\n",
    "\n",
    "data['totcost2014_zscore_bins'] = pd.cut(data['totcost2014_zscore'], \n",
    "                                        [np.NINF, -1, 1, np.Inf], labels = ['low', 'average','high'])\n",
    "data['los_zscore_bins'] = pd.cut(data['los_zscore'], \n",
    "                                         [np.NINF, -1, 1, np.Inf], labels = ['low', 'average','high'])\n",
    "data['totchg_2014_normalized_zscore_bins'] = pd.cut(data['totchg_2014_normalized_zscore'], \n",
    "                                        [np.NINF, -1, 1, np.Inf], labels = ['low', 'average','high'])\n",
    "                                                                      \n",
    "data = data[data.include == 1 ]\n",
    "# save for inspection\n",
    "data.to_csv('all_processed_NIS_TSA.csv', index = False)\n",
    "print('Done processing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['totcost2014'].notnull()]\n",
    "\n",
    "non_traumatic = data[(data.trauma == 0) & (data.hardware_failure == 0)]\n",
    "print(non_traumatic.shape)\n",
    "non_traumatic.to_csv('non_traumatic_TSA.csv', index = False)\n",
    "\n",
    "non_t_train, non_t_val, non_t_test = split_train_val_test(non_traumatic, 0.7, 0.1, 0.2)\n",
    "non_t_train.to_csv('non_traumatic_train.csv', index = False)\n",
    "non_t_val.to_csv('non_traumatic_validate.csv', index = False)\n",
    "non_t_test.to_csv('non_traumatic_test.csv', index = False)\n",
    "\n",
    "revision = data[data.hardware_failure == 1]\n",
    "print(revision.shape)\n",
    "revision.to_csv('hardware_failure_TSA.csv', index = False)\n",
    "\n",
    "r_train, r_val, r_test = split_train_val_test(revision, 0.7, 0.1, 0.2)\n",
    "r_train.to_csv('revision_train.csv', index = False)\n",
    "r_val.to_csv('revision_validate.csv', index = False)\n",
    "r_test.to_csv('revision_test.csv', index = False)\n",
    "\n",
    "traumatic = data[(data.trauma == 1) & (data.hardware_failure == 0)]\n",
    "print(traumatic.shape)\n",
    "traumatic.to_csv('traumatic_TSA.csv', index = False)\n",
    "\n",
    "t_train, t_val, t_test = split_train_val_test(traumatic, 0.7, 0.1, 0.2)\n",
    "t_train.to_csv('traumatic_train.csv', index = False)\n",
    "t_val.to_csv('traumatic_validate.csv', index = False)\n",
    "t_test.to_csv('traumatic_test.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
